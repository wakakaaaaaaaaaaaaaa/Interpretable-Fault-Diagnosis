{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "2\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from joblib import dump, load\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(100) \n",
    "device = 'cpu'\n",
    "\n",
    "def dataloader(batch_size, workers=2):\n",
    "    train_xdata = load('trainX_1024_10c')\n",
    "    train_ylabel = load('trainY_1024_10c')\n",
    "    val_xdata = load('valX_1024_10c')\n",
    "    val_ylabel = load('valY_1024_10c')\n",
    "    test_xdata = load('testX_1024_10c')\n",
    "    test_ylabel = load('testY_1024_10c')\n",
    "\n",
    "    train_loader = Data.DataLoader(dataset=Data.TensorDataset(train_xdata, train_ylabel),\n",
    "                                   batch_size=batch_size, shuffle=True, num_workers=workers, drop_last=True)\n",
    "    val_loader = Data.DataLoader(dataset=Data.TensorDataset(val_xdata, val_ylabel),\n",
    "                                 batch_size=batch_size, shuffle=True, num_workers=workers, drop_last=True)\n",
    "    test_loader = Data.DataLoader(dataset=Data.TensorDataset(test_xdata, test_ylabel),\n",
    "                                  batch_size=batch_size, shuffle=True, num_workers=workers, drop_last=True)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "batch_size = 32\n",
    "train_loader, val_loader, test_loader = dataloader(batch_size)\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class SiLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "class STSAM(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(STSAM, self).__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "        self.query_proj = nn.Conv2d(channels, channels, kernel_size=1, bias=False)\n",
    "        self.key_proj = nn.Conv2d(channels, channels, kernel_size=1, bias=False)\n",
    "        self.value_proj = nn.Conv2d(channels, channels, kernel_size=1, bias=False)\n",
    "\n",
    "        self.threshold_net = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1), \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels, channels // 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // 4, 1),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "\n",
    "        self.slope_net = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels // 4, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1), \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels // 4, 1),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def smooth_soft_threshold(self, x, threshold, slope):\n",
    "\n",
    "        threshold = threshold.view(-1, 1, 1)  \n",
    "        slope = slope.view(-1, 1, 1)\n",
    "        \n",
    "        abs_x = x.abs()\n",
    "        case1_mask = (abs_x <= threshold).float()  \n",
    "        case2_mask = 1 - case1_mask  \n",
    " \n",
    "        case1_value = slope * x\n",
    "        large_term = slope * threshold + (abs_x - slope * threshold) * (1 - torch.exp(-(abs_x - threshold)))\n",
    "        case2_value = torch.sign(x) * large_term\n",
    "\n",
    "        output = case1_mask * case1_value + case2_mask * case2_value\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        spatial_size = h * w\n",
    "\n",
    "        Q = self.query_proj(x).view(b, c, spatial_size).permute(0, 2, 1)  # [b, h*w, c]\n",
    "        K = self.key_proj(x).view(b, c, spatial_size)                    # [b, c, h*w]\n",
    "        V = self.value_proj(x).view(b, c, spatial_size).permute(0, 2, 1)  # [b, h*w, c]\n",
    "\n",
    "        attention_scores = torch.bmm(Q, K) / math.sqrt(c)  # [b, h*w, h*w]\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "\n",
    "        threshold = self.threshold_net(x)  # [b, 1]\n",
    "        slope = self.slope_net(x)          # [b, 1]\n",
    "\n",
    "        attention_weights_denoised = self.smooth_soft_threshold(attention_weights, threshold, slope)\n",
    "\n",
    "        out = torch.bmm(attention_weights_denoised, V)  # [b, h*w, c]\n",
    "        out = out.permute(0, 2, 1).view(b, c, h, w)     \n",
    "\n",
    "        self.attention_weights = attention_weights\n",
    "        self.attention_weights_denoised = attention_weights_denoised\n",
    "        self.threshold = threshold\n",
    "        self.slope = slope\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class IFMU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, grid_size=4):\n",
    "        super(IFMU, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.grid_size = grid_size\n",
    "        self.spline_order = 3  \n",
    "\n",
    "        self.conv_weight = nn.Parameter(\n",
    "            torch.Tensor(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        )\n",
    "        nn.init.kaiming_uniform_(self.conv_weight, a=math.sqrt(5))\n",
    "        \n",
    "\n",
    "        self.base_activation = SiLU()\n",
    "        self.num_knots = self.grid_size + self.spline_order + 1  \n",
    "        num_intervals = self.num_knots - 1 \n",
    "        self.num_bases = num_intervals - self.spline_order \n",
    "\n",
    "        \n",
    "        self.grid_points = nn.Parameter(\n",
    "            torch.linspace(-1, 1, self.num_knots).repeat(self.out_channels, 1),\n",
    "            requires_grad=True\n",
    "        )\n",
    "\n",
    "        self.spline_coeff = nn.Parameter(\n",
    "            torch.Tensor(out_channels, self.num_bases),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        nn.init.normal_(self.spline_coeff, mean=0.5, std=0.1) \n",
    "\n",
    "        self.base_weight = nn.Parameter(torch.ones(out_channels), requires_grad=True)\n",
    "        self.spline_weight = nn.Parameter(torch.full((out_channels,), 0.5), requires_grad=True)  \n",
    "\n",
    "        self.z = None\n",
    "        self.base_out = None\n",
    "        self.spline_out = None\n",
    "        self.spline_basis = None\n",
    "\n",
    "    def b_spline_basis(self, z, grid, order):\n",
    "        b, out_c, h, w = z.shape\n",
    "        num_knots = grid.shape[1]\n",
    "        num_intervals = num_knots - 1\n",
    "        num_bases = num_intervals - order\n",
    "\n",
    "        if order == 0:\n",
    "            grid_left = grid[:, :num_bases]  # [out_c, num_bases]\n",
    "            grid_right = grid[:, 1:num_bases+1]  # [out_c, num_bases]\n",
    "\n",
    "            grid_left_exp = grid_left.unsqueeze(0).unsqueeze(3).unsqueeze(4)\n",
    "            grid_right_exp = grid_right.unsqueeze(0).unsqueeze(3).unsqueeze(4)\n",
    "            z_exp = z.unsqueeze(2)\n",
    "\n",
    "            basis = ((z_exp >= grid_left_exp) & (z_exp < grid_right_exp)).float()\n",
    "\n",
    "            basis = basis + (grid.mean() * 1e-8)\n",
    "            \n",
    "            return basis\n",
    "\n",
    "        left_grid = grid[:, :-order]\n",
    "        left_grid_exp = left_grid.unsqueeze(0).unsqueeze(3).unsqueeze(4)\n",
    "        \n",
    "        grid_diff = grid[:, order:] - left_grid\n",
    "        left_denominator = grid_diff.unsqueeze(0).unsqueeze(3).unsqueeze(4) + 1e-8\n",
    "        \n",
    "        z_exp = z.unsqueeze(2)\n",
    "        left_numerator = z_exp - left_grid_exp\n",
    "        \n",
    "        left_coeff = left_numerator / left_denominator\n",
    "        \n",
    "        right_grid = grid[:, order:]\n",
    "        right_grid_exp = right_grid.unsqueeze(0).unsqueeze(3).unsqueeze(4)\n",
    "        right_numerator = right_grid_exp - z_exp\n",
    "        right_coeff = right_numerator / left_denominator\n",
    "        \n",
    "        lower_basis = self.b_spline_basis(z, grid, order - 1)\n",
    "        left_basis = lower_basis[:, :, :-1]\n",
    "        right_basis = lower_basis[:, :, 1:]\n",
    "        basis = left_coeff[:, :, :-1] * left_basis + right_coeff[:, :, 1:] * right_basis\n",
    "        basis = basis + (grid.mean() * 1e-8)\n",
    "        \n",
    "        return basis\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 2:\n",
    "            batch_size = x.size(0)\n",
    "            x = x.view(batch_size, 1, 32, 32)\n",
    "        \n",
    "        b, in_c, h, w = x.shape\n",
    "        self.z = F.conv2d(x, self.conv_weight, padding=self.padding)\n",
    "        self.base_out = self.base_weight.view(1, -1, 1, 1) * self.base_activation(self.z)\n",
    "        self.spline_basis = self.b_spline_basis(self.z, self.grid_points, self.spline_order)\n",
    "\n",
    "\n",
    "        self.spline_out = torch.sum(\n",
    "            self.spline_coeff.view(1, -1, self.num_bases, 1, 1) * self.spline_basis,\n",
    "            dim=2\n",
    "        )\n",
    "        self.spline_out = self.spline_weight.view(1, -1, 1, 1) * self.spline_out\n",
    "        self.z = self.z + self.spline_out * 0.1 \n",
    "\n",
    "        out = self.base_out + self.spline_out\n",
    "        spline_contribution = self.spline_out.abs().mean().item()\n",
    "        if spline_contribution < 1e-6:\n",
    "            print(f\"({spline_contribution:.8f})\")\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def _check_dependency(self, tensor, param):\n",
    "        if not tensor.requires_grad:\n",
    "            return False\n",
    "        try:\n",
    "            grad = torch.autograd.grad(\n",
    "                tensor, param, \n",
    "                grad_outputs=torch.ones_like(tensor),\n",
    "                retain_graph=True, \n",
    "                allow_unused=True\n",
    "            )[0]\n",
    "            return grad is not None and not torch.allclose(grad, torch.zeros_like(grad))\n",
    "        except:\n",
    "            return False\n",
    "class IFMU_STSAM_Model(nn.Module):\n",
    "    def __init__(self, output_dim=4, device='cpu'):\n",
    "        super(IFMU_STSAM_Model, self).__init__()\n",
    "        self.device = device\n",
    "        self.ifmu1 = IFMU(\n",
    "            in_channels=1, \n",
    "            out_channels=5, \n",
    "            kernel_size=3, \n",
    "            padding=1, \n",
    "            grid_size=4\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.ifmu2 = IFMU(\n",
    "            in_channels=5, \n",
    "            out_channels=25, \n",
    "            kernel_size=3, \n",
    "            padding=1, \n",
    "            grid_size=4\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.ifmu3 = IFMU(\n",
    "            in_channels=25, \n",
    "            out_channels=125, \n",
    "            kernel_size=3, \n",
    "            padding=1, \n",
    "            grid_size=4\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.stsam = STSAM(channels=125)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(125 * 4 * 4, 32)\n",
    "        self.fc2 = nn.Linear(32, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 2:\n",
    "            batch_size = x.size(0)\n",
    "            x = x.view(batch_size, 1, 32, 32)  \n",
    "        elif len(x.shape) == 3:\n",
    "            x = x.unsqueeze(1)  \n",
    "        x = self.ifmu1(x)\n",
    "        x = self.pool1(x)  # [b,5,16,16]\n",
    "        x = self.ifmu2(x)\n",
    "        x = self.pool2(x)  # [b,25,8,8]\n",
    "        x = self.ifmu3(x)\n",
    "        x = self.pool3(x)  # [b,125,4,4]\n",
    "        x = self.stsam(x)  # [b,125,4,4]\n",
    "        x = self.flatten(x)  # [b,2000]\n",
    "        x = self.fc1(x)      # [b,32]\n",
    "        x = self.fc2(x)      # [b,output_dim]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    45\n",
      "    40\n",
      "    20\n",
      "     5\n",
      "     5\n",
      "  1125\n",
      "   200\n",
      "   100\n",
      "    25\n",
      "    25\n",
      " 28125\n",
      "  1000\n",
      "   500\n",
      "   125\n",
      "   125\n",
      " 15625\n",
      " 15625\n",
      " 15625\n",
      "  3875\n",
      "    31\n",
      "    31\n",
      "     1\n",
      " 34875\n",
      "    31\n",
      "     1\n",
      " 64000\n",
      "    32\n",
      "   128\n",
      "     4\n",
      "______\n",
      "181349\n",
      "IFMU_STSAM_Model(\n",
      "  (ifmu1): IFMU(\n",
      "    (base_activation): SiLU()\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (ifmu2): IFMU(\n",
      "    (base_activation): SiLU()\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (ifmu3): IFMU(\n",
      "    (base_activation): SiLU()\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (stsam): STSAM(\n",
      "    (query_proj): Conv2d(125, 125, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (key_proj): Conv2d(125, 125, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (value_proj): Conv2d(125, 125, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (threshold_net): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "      (1): Flatten(start_dim=1, end_dim=-1)\n",
      "      (2): Linear(in_features=125, out_features=31, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Linear(in_features=31, out_features=1, bias=True)\n",
      "      (5): Sigmoid()\n",
      "    )\n",
      "    (slope_net): Sequential(\n",
      "      (0): Conv2d(125, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): AdaptiveAvgPool2d(output_size=1)\n",
      "      (3): Flatten(start_dim=1, end_dim=-1)\n",
      "      (4): Linear(in_features=31, out_features=1, bias=True)\n",
      "      (5): Sigmoid()\n",
      "    )\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=2000, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "output_dim = 4 \n",
    "\n",
    "model =IFMU_STSAM_Model(output_dim)  \n",
    "loss_function = nn.CrossEntropyLoss(reduction='sum')  # loss\n",
    "learn_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), learn_rate)  \n",
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "\n",
    "count_parameters(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time: 2025-09-28 16:12:45\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 90\u001b[0m\n\u001b[0;32m     88\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m     89\u001b[0m epochs \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 27\u001b[0m, in \u001b[0;36mmodel_train\u001b[1;34m(batch_size, epochs, model, optimizer, loss_function, train_loader, val_loader, device)\u001b[0m\n\u001b[0;32m     24\u001b[0m loss_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m   \n\u001b[0;32m     25\u001b[0m correct_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq, labels \u001b[38;5;129;01min\u001b[39;00m train_loader: \n\u001b[0;32m     28\u001b[0m     seq, labels \u001b[38;5;241m=\u001b[39m seq\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     29\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch2.2.2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch2.2.2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch2.2.2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch2.2.2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch2.2.2\\lib\\multiprocessing\\queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    106\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch2.2.2\\lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch2.2.2\\lib\\multiprocessing\\connection.py:330\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    328\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch2.2.2\\lib\\multiprocessing\\connection.py:879\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    877\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 879\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch2.2.2\\lib\\multiprocessing\\connection.py:811\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 811\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def model_train(batch_size, epochs, model, optimizer, loss_function, train_loader, val_loader, device):\n",
    "    model = model.to(device)\n",
    "    train_size = len(train_loader) * batch_size\n",
    "    val_size = len(val_loader) * batch_size\n",
    "    best_accuracy = 0.0\n",
    "    best_model = model\n",
    "\n",
    "    train_loss = []    \n",
    "    train_acc = []      \n",
    "    validate_acc = []\n",
    "    validate_loss = []\n",
    "    start_time = time.time()\n",
    "    print(f\"Training start time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "\n",
    "        loss_epoch = 0.   \n",
    "        correct_epoch = 0  \n",
    "        \n",
    "        for seq, labels in train_loader: \n",
    "            seq, labels = seq.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(seq)\n",
    "            probabilities = F.softmax(y_pred, dim=1)\n",
    "            predicted_labels = torch.argmax(probabilities, dim=1)\n",
    "            correct_epoch += (predicted_labels == labels).sum().item()\n",
    "            loss = loss_function(y_pred, labels)\n",
    "            loss_epoch += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_Accuracy  = correct_epoch / train_size \n",
    "        train_loss.append(loss_epoch / train_size)\n",
    "        train_acc.append(train_Accuracy)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            loss_validate = 0.\n",
    "            correct_validate = 0\n",
    "            for data, label in val_loader:\n",
    "                data, label = data.to(device), label.to(device)\n",
    "                pre = model(data)\n",
    "                probabilities = F.softmax(pre, dim=1)\n",
    "                predicted_labels = torch.argmax(probabilities, dim=1)\n",
    "                correct_validate += (predicted_labels == label).sum().item()\n",
    "                loss = loss_function(pre, label)\n",
    "                loss_validate += loss.item()\n",
    "            \n",
    "            val_accuracy = correct_validate / val_size \n",
    "            validate_loss.append(loss_validate / val_size)\n",
    "            validate_acc.append(val_accuracy)\n",
    "            if val_accuracy > best_accuracy:\n",
    "                best_accuracy = val_accuracy\n",
    "                best_model = model  \n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        print(f'Epoch: {epoch+1:2}/{epochs} | Time: {epoch_duration:.2f}s | '\n",
    "              f'train_Loss: {loss_epoch/train_size:10.8f} | train_Accuracy:{train_Accuracy:4.4f} | '\n",
    "              f'val_Loss:{loss_validate/val_size:10.8f} | validate_Acc:{val_accuracy:4.4f}')\n",
    "    \n",
    "    total_duration = time.time() - start_time\n",
    "    end_time = time.time()\n",
    "\n",
    "    torch.save(best_model, 'best_model_kanconv_senet.pt')\n",
    "   \n",
    "    print(f'\\nTraining completion time: {time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(end_time))}')\n",
    "    print(f'Total training time: {total_duration:.2f}s ({total_duration/60:.2f}min)')\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(epochs), train_loss, color='b', label='train_loss')\n",
    "    plt.plot(range(epochs), train_acc, color='g', label='train_acc')\n",
    "    plt.plot(range(epochs), validate_loss, color='y', label='validate_loss')\n",
    "    plt.plot(range(epochs), validate_acc, color='r', label='validate_acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Training Metrics')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Best validation set accuracy :\", best_accuracy)\n",
    "\n",
    "batch_size = 32\n",
    "epochs =100\n",
    "model_train(batch_size, epochs, model, optimizer, loss_function, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.2.2",
   "language": "python",
   "name": "pytorch2.2.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
