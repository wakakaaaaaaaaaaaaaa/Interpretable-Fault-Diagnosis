 "class SiLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "class STSAM(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(STSAM, self).__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "        self.query_proj = nn.Conv2d(channels, channels, kernel_size=1, bias=False)\n",
    "        self.key_proj = nn.Conv2d(channels, channels, kernel_size=1, bias=False)\n",
    "        self.value_proj = nn.Conv2d(channels, channels, kernel_size=1, bias=False)\n",
    "\n",
    "        self.threshold_net = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1), \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels, channels // 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // 4, 1),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "\n",
    "        self.slope_net = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels // 4, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1), \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels // 4, 1),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def smooth_soft_threshold(self, x, threshold, slope):\n",
    "\n",
    "        threshold = threshold.view(-1, 1, 1)  \n",
    "        slope = slope.view(-1, 1, 1)\n",
    "        \n",
    "        abs_x = x.abs()\n",
    "        case1_mask = (abs_x <= threshold).float()  \n",
    "        case2_mask = 1 - case1_mask  \n",
    " \n",
    "        case1_value = slope * x\n",
    "        large_term = slope * threshold + (abs_x - slope * threshold) * (1 - torch.exp(-(abs_x - threshold)))\n",
    "        case2_value = torch.sign(x) * large_term\n",
    "\n",
    "        output = case1_mask * case1_value + case2_mask * case2_value\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        spatial_size = h * w\n",
    "\n",
    "        Q = self.query_proj(x).view(b, c, spatial_size).permute(0, 2, 1)  # [b, h*w, c]\n",
    "        K = self.key_proj(x).view(b, c, spatial_size)                    # [b, c, h*w]\n",
    "        V = self.value_proj(x).view(b, c, spatial_size).permute(0, 2, 1)  # [b, h*w, c]\n",
    "\n",
    "        attention_scores = torch.bmm(Q, K) / math.sqrt(c)  # [b, h*w, h*w]\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "\n",
    "        threshold = self.threshold_net(x)  # [b, 1]\n",
    "        slope = self.slope_net(x)          # [b, 1]\n",
    "\n",
    "        attention_weights_denoised = self.smooth_soft_threshold(attention_weights, threshold, slope)\n",
    "\n",
    "        out = torch.bmm(attention_weights_denoised, V)  # [b, h*w, c]\n",
    "        out = out.permute(0, 2, 1).view(b, c, h, w)     \n",
    "\n",
    "        self.attention_weights = attention_weights\n",
    "        self.attention_weights_denoised = attention_weights_denoised\n",
    "        self.threshold = threshold\n",
    "        self.slope = slope\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class IFMU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, grid_size=4):\n",
    "        super(IFMU, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.grid_size = grid_size\n",
    "        self.spline_order = 3  \n",
    "\n",
    "        self.conv_weight = nn.Parameter(\n",
    "            torch.Tensor(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        )\n",
    "        nn.init.kaiming_uniform_(self.conv_weight, a=math.sqrt(5))\n",
    "        \n",
    "\n",
    "        self.base_activation = SiLU()\n",
    "        self.num_knots = self.grid_size + self.spline_order + 1  \n",
    "        num_intervals = self.num_knots - 1 \n",
    "        self.num_bases = num_intervals - self.spline_order \n",
    "\n",
    "        \n",
    "        self.grid_points = nn.Parameter(\n",
    "            torch.linspace(-1, 1, self.num_knots).repeat(self.out_channels, 1),\n",
    "            requires_grad=True\n",
    "        )\n",
    "\n",
    "        self.spline_coeff = nn.Parameter(\n",
    "            torch.Tensor(out_channels, self.num_bases),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        nn.init.normal_(self.spline_coeff, mean=0.5, std=0.1) \n",
    "\n",
    "        self.base_weight = nn.Parameter(torch.ones(out_channels), requires_grad=True)\n",
    "        self.spline_weight = nn.Parameter(torch.full((out_channels,), 0.5), requires_grad=True)  \n",
    "\n",
    "        self.z = None\n",
    "        self.base_out = None\n",
    "        self.spline_out = None\n",
    "        self.spline_basis = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 2:\n",
    "            batch_size = x.size(0)\n",
    "            x = x.view(batch_size, 1, 32, 32)\n",
    "        \n",
    "        b, in_c, h, w = x.shape\n",
    "        self.z = F.conv2d(x, self.conv_weight, padding=self.padding)\n",
    "        self.base_out = self.base_weight.view(1, -1, 1, 1) * self.base_activation(self.z)\n",
    "        self.spline_basis = self.b_spline_basis(self.z, self.grid_points, self.spline_order)\n",
    "\n",
    "\n",
    "        self.spline_out = torch.sum(\n",
    "            self.spline_coeff.view(1, -1, self.num_bases, 1, 1) * self.spline_basis,\n",
    "            dim=2\n",
    "        )\n",
    "        self.spline_out = self.spline_weight.view(1, -1, 1, 1) * self.spline_out\n",
    "        self.z = self.z + self.spline_out * 0.1 \n",
    "\n",
    "        out = self.base_out + self.spline_out\n",
    "        spline_contribution = self.spline_out.abs().mean().item()\n",
    "        if spline_contribution < 1e-6:\n",
    "            print(f\"({spline_contribution:.8f})\")\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def _check_dependency(self, tensor, param):\n",
    "        if not tensor.requires_grad:\n",
    "            return False\n",
    "        try:\n",
    "            grad = torch.autograd.grad(\n",
    "                tensor, param, \n",
    "                grad_outputs=torch.ones_like(tensor),\n",
    "                retain_graph=True, \n",
    "                allow_unused=True\n",
    "            )[0]\n",
    "            return grad is not None and not torch.allclose(grad, torch.zeros_like(grad))\n",
    "        except:\n",
    "            return False\n",
    "class IFMU_STSAM_Model(nn.Module):\n",
    "    def __init__(self, output_dim=4, device='cpu'):\n",
    "        super(IFMU_STSAM_Model, self).__init__()\n",
    "        self.device = device\n",
    "        self.ifmu1 = IFMU(\n",
    "            in_channels=1, \n",
    "            out_channels=5, \n",
    "            kernel_size=3, \n",
    "            padding=1, \n",
    "            grid_size=4\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.ifmu2 = IFMU(\n",
    "            in_channels=5, \n",
    "            out_channels=25, \n",
    "            kernel_size=3, \n",
    "            padding=1, \n",
    "            grid_size=4\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.ifmu3 = IFMU(\n",
    "            in_channels=25, \n",
    "            out_channels=125, \n",
    "            kernel_size=3, \n",
    "            padding=1, \n",
    "            grid_size=4\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.stsam = STSAM(channels=125)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(125 * 4 * 4, 32)\n",
